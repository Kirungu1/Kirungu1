{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Kirungu1/Kirungu1/blob/main/04_irises.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "Simple implementation of iris recognition based on Domain-specific Human-inspired Binarized Statistical Image Features (DHBSIF), peer-reviewed and published [here](https://ieeexplore.ieee.org/document/8658238).  \n",
        "\n",
        "Language: Python 3  \n",
        "\n",
        "Needed libraries:\n",
        "* NumPy (https://numpy.org/)\n",
        "* matplotlib (https://matplotlib.org/)\n",
        "* OpenCV (https://opencv.org/)\n",
        "* SciPy (https://scipy.org/)"
      ],
      "metadata": {
        "id": "W2h79Hrpn2yV"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Needed libraries and files"
      ],
      "metadata": {
        "id": "GFbH4mo7v2QR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# download of iris files for proper tests\n",
        "!pip install gdown\n",
        "!gdown 18czPqnf4cqxIPEXo0Mz1xi5IPHEWaGMR\n",
        "!gdown 1AzZCeFEIPYLKCelNLvickiI2qWjJ12Eg\n",
        "!gdown 1rsQNGzHRdBXMj0Ebt6irRRFA6cuPke4h\n",
        "!gdown 1rSUP6ADFuaIr_XxAh72qtvsieKSqOwS2"
      ],
      "metadata": {
        "id": "4so07XqKn2UE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# download of domain-specific human-inspired BSIF filters\n",
        "!gdown 1IrcAXVCVd_3hBOyQN0rFyxMK6uH0MN73"
      ],
      "metadata": {
        "id": "sOZKOzS4nPKU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# imported libraries\n",
        "import numpy as np\n",
        "print('NumPy version', np.__version__)\n",
        "\n",
        "import matplotlib as plt\n",
        "print('Matplotlib version', plt.__version__)\n",
        "\n",
        "import cv2\n",
        "print('OpenCV version', cv2.__version__)\n",
        "\n",
        "import scipy\n",
        "print('SciPy version', scipy.__version__)"
      ],
      "metadata": {
        "id": "NtGDeQHoQbMb",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "869bca40-df81-487a-e7d7-03ce7052daf9"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "NumPy version 1.26.4\n",
            "Matplotlib version 3.7.1\n",
            "OpenCV version 4.10.0\n",
            "SciPy version 1.13.1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "--------------------------\n",
        "## Iris acquisition"
      ],
      "metadata": {
        "id": "c0XQVqN-O90F"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Main function"
      ],
      "metadata": {
        "id": "cQI1_EPdeyl9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Acquires an iris from an image file, given its path.\n",
        "# Parameters:\n",
        "# <file_path> - The path to the image file containing the iris.\n",
        "# <view> - True if the loaded image must be shown, False otherwise.\n",
        "# Returns the obtained image as a numpy 2D uint8 array.\n",
        "def acquire_from_file(file_path, view=False):\n",
        "    # reads the image from the given file path\n",
        "    # and returns it\n",
        "    iris = cv2.imread(file_path)\n",
        "\n",
        "    # shows the read image, if it is the case\n",
        "    if view:\n",
        "        plt.pyplot.imshow(cv2.cvtColor(iris, cv2.COLOR_BGR2RGB))\n",
        "        plt.pyplot.title('Iris acquisition')\n",
        "        plt.pyplot.show()\n",
        "\n",
        "    return iris"
      ],
      "metadata": {
        "id": "0YBC6wwrPZU-"
      },
      "execution_count": 38,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# tests the iris acquisition\n",
        "iris_1 = acquire_from_file('/content/eye_011.png', view=True)\n",
        "print('Image resolution:', iris_1.shape, '\\n')\n",
        "\n",
        "iris_2 = acquire_from_file('/content/eye_012.png', view=True)\n",
        "print('Image resolution:', iris_2.shape)"
      ],
      "metadata": {
        "id": "tO5FGJEFQZfu",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 332
        },
        "outputId": "5cf5aa62-184e-497e-fac4-447007c63423"
      },
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "error",
          "ename": "AttributeError",
          "evalue": "module 'matplotlib.pyplot' has no attribute 'pyplot'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-39-74f6ea1e9fe9>\u001b[0m in \u001b[0;36m<cell line: 2>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# tests the iris acquisition\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0miris_1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0macquire_from_file\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'/content/eye_011.png'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mview\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Image resolution:'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0miris_1\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'\\n'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0miris_2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0macquire_from_file\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'/content/eye_012.png'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mview\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-38-06f50f691242>\u001b[0m in \u001b[0;36macquire_from_file\u001b[0;34m(file_path, view)\u001b[0m\n\u001b[1;32m     11\u001b[0m     \u001b[0;31m# shows the read image, if it is the case\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mview\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 13\u001b[0;31m         \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpyplot\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimshow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcv2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcvtColor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miris\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcv2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mCOLOR_BGR2RGB\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     14\u001b[0m         \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpyplot\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtitle\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Iris acquisition'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m         \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpyplot\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mAttributeError\u001b[0m: module 'matplotlib.pyplot' has no attribute 'pyplot'"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "--------------------------\n",
        "## Iris enhancement"
      ],
      "metadata": {
        "id": "yp6AcBTzRqgN"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Main steps\n",
        "* <code>_01_preprocess</code>: to preprocess the given image, resizing and bringing it to grayscale.\n",
        "* <code>_02_detect_pupil</code>: to detect the pupil circle.\n",
        "* <code>_03_detect_limbus</code>: to detect the limbus circle.\n",
        "* <code>_04_compute_mask</code>: to mask the iris in and filter everything else out.\n",
        "* <code>_05_normalize_iris</code>: to normalize the iris content into a rectangle."
      ],
      "metadata": {
        "id": "8tFxDsurR-w6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Preprocesses the given <iris> image (numpy 2D array with uint8 pixel values).\n",
        "# Provide <view> as True if you want to see the result of computations.\n",
        "# Returns the preprocessed iris as a numpy 2D uint8 array.\n",
        "def _01_preprocess(iris, iris_width=640, view=False):\n",
        "    # makes the iris grayscale, if it has color information\n",
        "    if len(iris.shape) > 2 and iris.shape[2] > 1:  # more than one channel?\n",
        "        iris = cv2.cvtColor(iris, cv2.COLOR_BGR2GRAY)\n",
        "\n",
        "    # resizes the iris to present a width of <iris_width> pixels,\n",
        "    # keeping the original aspect ratio\n",
        "    aspect_ratio = float(iris.shape[0]) / iris.shape[1]\n",
        "    height = int(round(iris_width * aspect_ratio))\n",
        "    iris = cv2.resize(iris, (iris_width, height))\n",
        "\n",
        "    # shows the obtained iris, if it is the case\n",
        "    if view:\n",
        "        plt.pyplot.imshow(iris, cmap='gray')\n",
        "        plt.pyplot.title('Iris preprocessing')\n",
        "        plt.pyplot.show()\n",
        "\n",
        "    return iris"
      ],
      "metadata": {
        "id": "SoeZn6Y7SMdi"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# tests the iris pre-processing\n",
        "pp_iris_1 = _01_preprocess(iris_1, view=True)\n",
        "print('Image resolution:', pp_iris_1.shape, '\\n')\n",
        "\n",
        "pp_iris_2 = _01_preprocess(iris_2, view=True)\n",
        "print('Image resolution:', pp_iris_2.shape, '\\n')"
      ],
      "metadata": {
        "id": "KyeVRZNnTIKr",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 211
        },
        "outputId": "05d0ab79-0020-45c6-b127-b9b4d6bf5842"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "name 'iris_1' is not defined",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-18-8542ae5d151a>\u001b[0m in \u001b[0;36m<cell line: 2>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# tests the iris pre-processing\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mpp_iris_1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_01_preprocess\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miris_1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mview\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Image resolution:'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpp_iris_1\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'\\n'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mpp_iris_2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_01_preprocess\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miris_2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mview\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'iris_1' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Detects the pupil over the given <iris> leveraging the OpenCV\n",
        "# implementation of blob detection; the pupil is a blob.\n",
        "# Provide <view> as True if you want to see the result of computation.\n",
        "# Returns the pupil circle (x_center, y_center, radius), in pixels.\n",
        "# Returns None if no pupil is found.\n",
        "def _02_detect_pupil(iris, iris_blur_size=31, iris_min_rad=20, view=False):\n",
        "  # sharpens the iris texture and min-max normalizes it in the [0,255] interval\n",
        "  blur_iris = cv2.medianBlur(iris, iris_blur_size)\n",
        "  blur_iris = iris - blur_iris\n",
        "\n",
        "  if view:\n",
        "    plt.pyplot.imshow(blur_iris, cmap='gray')\n",
        "    plt.pyplot.title('Sharp iris')\n",
        "    plt.pyplot.show()\n",
        "\n",
        "  # blob detection with OpenCV\n",
        "  blob_detection = cv2.SimpleBlobDetector_Params()\n",
        "  blob_detection.filterByArea = True\n",
        "  blob_detection.minArea = int(np.pi * iris_min_rad ** 2)\n",
        "  blob_detection.maxArea = int(np.pi * (iris_min_rad * 4) ** 2)\n",
        "  blob_detector = cv2.SimpleBlobDetector_create(blob_detection)\n",
        "  blobs = blob_detector.detect(blur_iris)\n",
        "\n",
        "  # takes the pupil as the largest blob\n",
        "  pupil = None\n",
        "  ref_size = 0\n",
        "\n",
        "  for blob in blobs:\n",
        "    if blob.size > ref_size:\n",
        "      pupil = (int(blob.pt[0]), int(blob.pt[1]), int(blob.size / 2))\n",
        "      ref_size = blob.size\n",
        "\n",
        "  # shows the obtained pupil, if it is the case\n",
        "  if view:\n",
        "    iris_copy = cv2.cvtColor(iris, cv2.COLOR_GRAY2BGR)\n",
        "\n",
        "    if pupil is not None:\n",
        "      cv2.circle(iris_copy, pupil[0:2], pupil[2], (0, 255, 0), 1)\n",
        "\n",
        "    plt.pyplot.imshow(cv2.cvtColor(iris_copy, cv2.COLOR_BGR2RGB))\n",
        "    plt.pyplot.title('Pupil on iris')\n",
        "    plt.pyplot.show()\n",
        "\n",
        "  # returns the obtained pupil\n",
        "  return pupil"
      ],
      "metadata": {
        "id": "MqNBTStxe6Ta"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# tests the pupil detection\n",
        "pupil_1 = _02_detect_pupil(pp_iris_1, view=True)\n",
        "print('\\n')\n",
        "\n",
        "pupil_2 = _02_detect_pupil(pp_iris_2, view=True)"
      ],
      "metadata": {
        "id": "KAyGPvbziW80",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 211
        },
        "outputId": "0fc7ae21-d571-4874-e1ec-7ae9ad54bbe6"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "name 'pp_iris_1' is not defined",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-21-d69f4eeb76e5>\u001b[0m in \u001b[0;36m<cell line: 2>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# tests the pupil detection\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mpupil_1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_02_detect_pupil\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpp_iris_1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mview\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'\\n'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mpupil_2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_02_detect_pupil\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpp_iris_2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mview\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'pp_iris_1' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Detects the limbus over the given <iris>, by finding the limbus circle\n",
        "# with the best fit to the Laplacian of Gaussian of the iris.\n",
        "# Provide <view> as True if you want to see the result of computations.\n",
        "# Returns the limbus circle (x_center, y_center, radius), in pixels.\n",
        "# Returns None if no limbus is found.\n",
        "def _03_detect_limbus(iris, pupil,\n",
        "                      blur_size=3, limbus_offset_ratio=3.0,\n",
        "                      limbus_min_pupil_ratio = 1.4,\n",
        "                      limbus_max_pupil_ratio = 4.4,\n",
        "                      view=False):\n",
        "  # computes the LoG of the given iris\n",
        "  gauss_iris = cv2.GaussianBlur(iris, (blur_size, blur_size), 0)\n",
        "  log_iris = (cv2.Laplacian(gauss_iris, cv2.CV_32F, None, blur_size) > 0).astype(np.uint8)\n",
        "\n",
        "  if view:\n",
        "    plt.pyplot.imshow(log_iris, cmap='gray')\n",
        "    plt.pyplot.title('LoG iris')\n",
        "    plt.pyplot.show()\n",
        "\n",
        "  # finds the best fitting circle to the LoG iris\n",
        "  best_limbus_pos = None\n",
        "  best_limbus_sum = 0.0\n",
        "  best_limbus_rad = 0\n",
        "\n",
        "  limbus_offset = int(pupil[2] / limbus_offset_ratio)\n",
        "  for limbus_radius in range(int(pupil[2] * limbus_min_pupil_ratio),\n",
        "                             int(pupil[2] * limbus_max_pupil_ratio), 2):\n",
        "    for x in range(pupil[0] - limbus_offset, pupil[0] + limbus_offset, 2):\n",
        "      for y in range(pupil[1] - limbus_offset, pupil[1] + limbus_offset, 2):\n",
        "        limbus_mask_i = np.zeros(iris.shape, np.uint8)\n",
        "        cv2.circle(limbus_mask_i, (x, y), limbus_radius, (255, 255, 255), 1)\n",
        "\n",
        "        limbus_sum = np.sum(cv2.bitwise_and(log_iris, log_iris, mask=limbus_mask_i)).astype(np.float32) / (2 * np.pi * (limbus_radius))\n",
        "        if limbus_sum > best_limbus_sum or (limbus_sum == best_limbus_sum and limbus_radius > best_limbus_rad):\n",
        "          best_limbus_pos = (x, y)\n",
        "          best_limbus_sum = limbus_sum\n",
        "          best_limbus_rad = limbus_radius\n",
        "\n",
        "  # sets the obtained limbus\n",
        "  limbus = None\n",
        "  if best_limbus_pos is not None:\n",
        "    limbus = (best_limbus_pos[0], best_limbus_pos[1], best_limbus_rad)\n",
        "\n",
        "  # shows the obtained limbus=, if it is the case\n",
        "  if view:\n",
        "    iris_copy = cv2.cvtColor(iris, cv2.COLOR_GRAY2BGR)\n",
        "\n",
        "    if limbus is not None:\n",
        "      cv2.circle(iris_copy, limbus[0:2], limbus[2], (0, 255, 0), 1)\n",
        "\n",
        "    plt.pyplot.imshow(cv2.cvtColor(iris_copy, cv2.COLOR_BGR2RGB))\n",
        "    plt.pyplot.title('Limbus on iris')\n",
        "    plt.pyplot.show()\n",
        "\n",
        "  # returns the obtained limbus\n",
        "  return limbus"
      ],
      "metadata": {
        "id": "tcc6NUPO7Ko2"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# tests the limbus detection\n",
        "limbus_1 = _03_detect_limbus(pp_iris_1, pupil_1, view=True)\n",
        "print('\\n')\n",
        "\n",
        "limbus_2 = _03_detect_limbus(pp_iris_2, pupil_2, view=True)"
      ],
      "metadata": {
        "id": "ZJWRKq-tnObT",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 211
        },
        "outputId": "109e4c23-ee25-40a3-e0cb-7119b11a8bd1"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "name 'pp_iris_1' is not defined",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-23-7f04b368c935>\u001b[0m in \u001b[0;36m<cell line: 2>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# tests the limbus detection\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mlimbus_1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_03_detect_limbus\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpp_iris_1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpupil_1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mview\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'\\n'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mlimbus_2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_03_detect_limbus\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpp_iris_2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpupil_2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mview\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'pp_iris_1' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Computes a mask to remove eye lashes and specular highlights from the given <iris>.\n",
        "# This process needs the <pupil> and <limbus> circles to execute the proper segmentation.\n",
        "# Provide <view> as True if you want to see the result of computations.\n",
        "# Returns the computed mask as a numpy 2D uint8 array, which is black (zero) for the areas to be ignored, and\n",
        "# white (255) for the ones to be processed.\n",
        "def _04_compute_mask(iris, pupil, limbus,\n",
        "                     eyelash_value=25, spec_value=254,\n",
        "                     view=False):\n",
        "    # computed mask\n",
        "    mask = np.zeros(iris.shape, np.uint8)\n",
        "\n",
        "    # adds limbus and pupil regions to the mask\n",
        "    cv2.circle(mask, limbus[0:2], limbus[2], (255, 255, 255), -1)\n",
        "    cv2.circle(mask, pupil[0:2], pupil[2], (0, 0, 0), -1)\n",
        "\n",
        "    # removes eventual eye lashes (black) and specular highlights (white)\n",
        "    eq_iris = cv2.bitwise_and(iris, iris, mask=mask)\n",
        "    eq_iris = cv2.equalizeHist(eq_iris)\n",
        "    eq_iris = cv2.normalize(eq_iris, None, 0, 255, cv2.NORM_MINMAX)\n",
        "    _, m_lashes = cv2.threshold(eq_iris, eyelash_value, 255, cv2.THRESH_BINARY)\n",
        "    _, m_specul = cv2.threshold(eq_iris, spec_value, 255, cv2.THRESH_BINARY_INV)\n",
        "\n",
        "    # final mask\n",
        "    mask = cv2.bitwise_and(m_lashes, m_specul, mask=mask)\n",
        "\n",
        "    # shows the obtained mask, if it is the case\n",
        "    if view:\n",
        "        mask_iris = cv2.bitwise_and(iris, iris, mask=mask)\n",
        "        plt.pyplot.imshow(mask_iris, cmap='gray')\n",
        "        plt.pyplot.title('Masked iris')\n",
        "        plt.pyplot.show()\n",
        "\n",
        "    return mask"
      ],
      "metadata": {
        "id": "AOspYMW97ynL"
      },
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# tests iris masking\n",
        "mask_1 = _04_compute_mask(pp_iris_1, pupil_1, limbus_1, view=True)\n",
        "print('\\n')\n",
        "\n",
        "mask_2 = _04_compute_mask(pp_iris_2, pupil_2, limbus_2, view=True)"
      ],
      "metadata": {
        "id": "Z6z-gpI98XJc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Normalizes the given <iris> making it a proper rectangle (rubber sheet algorithm).\n",
        "# This process needs the <pupil> and <limbus> circles, as well as the iris useful content <mask>\n",
        "# to execute the proper normalization.\n",
        "# Provide <view> as True if you want to see the result of computations.\n",
        "# Returns the normalized iris and respective normalized mask as numpy 2D uint8 arrays.\n",
        "def _05_normalize_iris(iris, pupil, limbus, mask,\n",
        "                       norm_iris_width=512, norm_iris_height=64,\n",
        "                       norm_iris_sector_count=1000,\n",
        "                       view=False):\n",
        "    # iris band width\n",
        "    iris_band_width = limbus[2] - pupil[2]\n",
        "\n",
        "    # output normalized iris\n",
        "    norm_iris = np.zeros((iris_band_width, norm_iris_sector_count), np.uint8)\n",
        "    norm_mask = np.zeros((iris_band_width, norm_iris_sector_count), np.uint8)\n",
        "\n",
        "    # for each sector...\n",
        "    j = 0\n",
        "    for angle in np.arange(0, 2.0 * np.pi, 2.0 * np.pi / norm_iris_sector_count):\n",
        "        # for each iris band pixel...\n",
        "        for i in range(iris_band_width):\n",
        "            # cartesian position\n",
        "            x = int(round(pupil[0] + (pupil[2] + i + 1) * np.sin(angle)))\n",
        "            y = int(round(pupil[1] + (pupil[2] + i + 1) * np.cos(angle)))\n",
        "\n",
        "            # pixel-value transference\n",
        "            norm_iris[i, j] = iris[y, x]\n",
        "            norm_mask[i, j] = mask[y, x]\n",
        "\n",
        "        # next sector\n",
        "        j = j + 1\n",
        "\n",
        "    # resizes the normalized iris and mask\n",
        "    norm_iris = cv2.resize(norm_iris, (norm_iris_width, norm_iris_height),\n",
        "                           interpolation=cv2.INTER_CUBIC)\n",
        "    norm_iris = cv2.equalizeHist(norm_iris)\n",
        "\n",
        "    norm_mask = cv2.resize(norm_mask, (norm_iris_width, norm_iris_height),\n",
        "                           interpolation=cv2.INTER_CUBIC)\n",
        "    _, norm_mask = cv2.threshold(norm_mask, 0, 255, cv2.THRESH_BINARY)\n",
        "\n",
        "    if view:\n",
        "      norm_view = np.vstack((norm_iris, norm_mask))\n",
        "      plt.pyplot.imshow(norm_view, cmap='gray')\n",
        "      plt.pyplot.title('Normalized iris')\n",
        "      plt.pyplot.show()\n",
        "\n",
        "    # returns the obtained normalized iris and mask\n",
        "    return norm_iris, norm_mask"
      ],
      "metadata": {
        "id": "82w0sW-M_jNC"
      },
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# tests iris normalization\n",
        "norm_iris_1, norm_mask_1 = _05_normalize_iris(pp_iris_1, pupil_1, limbus_1, mask_1, view=True)\n",
        "print('\\n')\n",
        "\n",
        "norm_iris_2, norm_mask_2 = _05_normalize_iris(pp_iris_2, pupil_2, limbus_2, mask_2, view=True)"
      ],
      "metadata": {
        "id": "shypZuJwA0rh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Main function"
      ],
      "metadata": {
        "id": "11OdbvM4Bh-G"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Enhances the given <iris> image (numpy 2-D array with uint8 pixel values).\n",
        "# Provide <view> as True if you want to see the results of computations.\n",
        "# Returns the normalized iris and respective normalized mask as numpy 2D uint8 arrays.\n",
        "def enhance(iris, view=False):\n",
        "    # pre-processes the iris\n",
        "    pp_iris = _01_preprocess(iris, view=view)\n",
        "\n",
        "    # detects the pupil\n",
        "    pupil = _02_detect_pupil(pp_iris)\n",
        "    if pupil is None:\n",
        "        return None\n",
        "\n",
        "    # detects the limbus\n",
        "    limbus = _03_detect_limbus(pp_iris, pupil)\n",
        "    if limbus is None:\n",
        "        return None\n",
        "\n",
        "    # shows pupil and limbus, if this is the case\n",
        "    if view:\n",
        "      view_pupil_limbus = cv2.cvtColor(pp_iris, cv2.COLOR_GRAY2BGR)\n",
        "      cv2.circle(view_pupil_limbus, pupil[0:2], pupil[2], (0, 255, 0), 1)\n",
        "      cv2.circle(view_pupil_limbus, limbus[0:2], limbus[2], (0, 0, 255), 1)\n",
        "\n",
        "      plt.pyplot.imshow(cv2.cvtColor(view_pupil_limbus, cv2.COLOR_BGR2RGB))\n",
        "      plt.pyplot.title('Pupil and limbus')\n",
        "      plt.pyplot.show()\n",
        "\n",
        "    # computes the mask that will remove the noise from the iris texture\n",
        "    mask = _04_compute_mask(pp_iris, pupil, limbus, view=view)\n",
        "\n",
        "    # computes the normalized iris\n",
        "    norm_iris, norm_mask = _05_normalize_iris(pp_iris, pupil, limbus, mask, view=view)\n",
        "\n",
        "    return norm_iris, norm_mask"
      ],
      "metadata": {
        "id": "yQaP3kZ9Bh-H"
      },
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# tests the enhancement function\n",
        "iris_1 = acquire_from_file('/content/eye_011.png')\n",
        "iris_2 = acquire_from_file('/content/eye_012.png')\n",
        "\n",
        "norm_iris_1, mask_iris_1 = enhance(iris_1, view=True)\n",
        "print('\\n')\n",
        "\n",
        "norm_iris_2, mask_iris_2 = enhance(iris_2, view=True)"
      ],
      "metadata": {
        "id": "EyKT9H4jBh-H"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "--------------------------\n",
        "## Iris description\n",
        "\n"
      ],
      "metadata": {
        "id": "lE5NpNYBe5BJ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Main function"
      ],
      "metadata": {
        "id": "PfsQzgSMfBMe"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Describes the given normalized iris <norm_iris> with BSIF filters.\n",
        "# Provide <view> as True if you want to see the results of computations.\n",
        "# Returns the obtained binary descriptions.\n",
        "def describe(norm_iris,\n",
        "             filter_file_path='/content/ICAtextureFilters_15x15_7bit.mat',\n",
        "             view=False):\n",
        "    # BSIF filters learned from the eye-tracking data\n",
        "    filters = scipy.io.loadmat(filter_file_path)['ICAtextureFilters']\n",
        "    filter_count = filters.shape[2]\n",
        "    filter_size = filters.shape[0]\n",
        "\n",
        "    # output binary code\n",
        "    descriptions = np.zeros((norm_iris.shape[0], norm_iris.shape[1], filter_count))\n",
        "\n",
        "    # prepares the iris image to be convolved with the BSIF filters\n",
        "    offset = int(filter_size / 2)\n",
        "    iris_wrap = np.zeros((offset*2 + norm_iris.shape[0], offset*2 + norm_iris.shape[1]))\n",
        "\n",
        "    iris_wrap[offset:-offset, offset:-offset] = norm_iris\n",
        "    iris_wrap[offset:-offset, :offset] = norm_iris[:, -offset:]\n",
        "    iris_wrap[offset:-offset, -offset:] = norm_iris[:, :offset]\n",
        "    iris_wrap[offset-1:0:-1, :] = iris_wrap[offset:(offset*2)-1, :]\n",
        "    iris_wrap[-offset:, :] = iris_wrap[-offset-1:(-offset*2)-1:-1, :]\n",
        "\n",
        "    if view:\n",
        "      plt.pyplot.imshow(iris_wrap, cmap='gray')\n",
        "      plt.pyplot.title('Iris wrap')\n",
        "      plt.pyplot.show()\n",
        "\n",
        "    # for each filter, applies the convolution with the iris image\n",
        "    for i in range(filter_count):\n",
        "        conv = scipy.signal.convolve2d(iris_wrap, np.rot90(filters[:, :, filter_count - i - 1], 2), mode='valid')\n",
        "        descriptions[:, :, i] = conv > 0.0  # binarization\n",
        "\n",
        "        # shows the current convolved image, if it is the case\n",
        "        if view:\n",
        "            view_conv = cv2.normalize(conv, None, alpha=0, beta=255, norm_type=cv2.NORM_MINMAX).astype(np.uint8)\n",
        "            plt.pyplot.imshow(cv2.cvtColor(view_conv, cv2.COLOR_BGR2RGB))\n",
        "            plt.pyplot.title('Filtered iris ' + str(i + 1))\n",
        "            plt.pyplot.show()\n",
        "\n",
        "            view_code = descriptions[:, :, i].astype(np.uint8) * 255\n",
        "            plt.pyplot.imshow(cv2.cvtColor(view_code, cv2.COLOR_BGR2RGB))\n",
        "            plt.pyplot.title('Iris code ' + str(i + 1))\n",
        "            plt.pyplot.show()\n",
        "\n",
        "    return descriptions"
      ],
      "metadata": {
        "id": "tIp4JserfDaH"
      },
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# tests the description function\n",
        "iris_1 = acquire_from_file('/content/eye_011.png')\n",
        "iris_2 = acquire_from_file('/content/eye_012.png')\n",
        "\n",
        "norm_iris_1, mask_iris_1 = enhance(iris_1)\n",
        "norm_iris_2, mask_iris_2 = enhance(iris_2)\n",
        "\n",
        "desc_1 = describe(norm_iris_1, view=True)\n",
        "print('Description:', desc_1.shape, '\\n')\n",
        "\n",
        "desc_2 = describe(norm_iris_2, view=True)\n",
        "print('Description:', desc_2.shape)"
      ],
      "metadata": {
        "id": "RkOeNGkRhcrx",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 356
        },
        "outputId": "c9812822-3561-4f0d-c4d7-e0561e714187"
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "error",
          "ename": "AttributeError",
          "evalue": "'NoneType' object has no attribute 'shape'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-29-132c086c4081>\u001b[0m in \u001b[0;36m<cell line: 5>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0miris_2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0macquire_from_file\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'/content/eye_012.png'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0mnorm_iris_1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmask_iris_1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0menhance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miris_1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m \u001b[0mnorm_iris_2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmask_iris_2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0menhance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miris_2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-26-2328beccf13b>\u001b[0m in \u001b[0;36menhance\u001b[0;34m(iris, view)\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0menhance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miris\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mview\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0;31m# pre-processes the iris\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m     \u001b[0mpp_iris\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_01_preprocess\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miris\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mview\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mview\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m     \u001b[0;31m# detects the pupil\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-16-1864878c99f9>\u001b[0m in \u001b[0;36m_01_preprocess\u001b[0;34m(iris, iris_width, view)\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0m_01_preprocess\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miris\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0miris_width\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m640\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mview\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0;31m# makes the iris grayscale, if it has color information\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m     \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miris\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m2\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0miris\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# more than one channel?\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m         \u001b[0miris\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcv2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcvtColor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miris\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcv2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mCOLOR_BGR2GRAY\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mAttributeError\u001b[0m: 'NoneType' object has no attribute 'shape'"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "-----------------------\n",
        "## Iris matching"
      ],
      "metadata": {
        "id": "mieWraYyfDnQ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Auxiliary functions\n",
        "* <code>_rotate_norm_image</code>: to rotate the binary code to cope with eventual head tilt during iris capture.\n",
        "* <code>_compute_norm_hamming_distance</code>: to compute the distance between two given iris descriptions."
      ],
      "metadata": {
        "id": "QdoNwPFNlYRF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Shifts the given iris binary code <image> according to the given <rotation>,\n",
        "# in pixels. Returns the rotated code.\n",
        "def _rotate_norm_image(image, rotation):\n",
        "    output = np.zeros(image.shape, image.dtype)\n",
        "\n",
        "    if rotation == 0:\n",
        "        return image\n",
        "\n",
        "    else:\n",
        "        output[:, rotation:] = image[:, :-rotation]\n",
        "        output[:, :rotation] = image[:, -rotation:]\n",
        "\n",
        "    return output"
      ],
      "metadata": {
        "id": "PPm5tSXoi6Sa"
      },
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Computes the hamming distance between the given iris binary codes <description_1> and <description_2>,\n",
        "# observing their respective masks <mask_1> and <mask_2>.\n",
        "# Returns the normalized iris code distance as a positive real value.\n",
        "def _compute_norm_hamming_distance(description_1, mask_1, description2, mask_2):\n",
        "    # combines both masks\n",
        "    comb_mask = cv2.bitwise_and(mask_1, mask_2)\n",
        "\n",
        "    # computes the number of bits up within the resulting mask\n",
        "    bit_up_count = np.sum(comb_mask > 0)\n",
        "\n",
        "    # hamming distance\n",
        "    xor_output = cv2.bitwise_xor(description_1, description2)\n",
        "    xor_output = cv2.bitwise_and(xor_output, xor_output, mask=comb_mask)\n",
        "    dist = np.sum(xor_output > 0)\n",
        "\n",
        "    # returns the normalized hamming distance\n",
        "    return float(dist) / bit_up_count"
      ],
      "metadata": {
        "id": "0WwVL9MwM9-7"
      },
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Main function"
      ],
      "metadata": {
        "id": "vGxwaSKWPqcg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Matches the given iris binary codes <description_1> and <description_2>,\n",
        "# observing their respective masks <mask_1> and <mask_2>.\n",
        "# Returns the distance between the given iris codes, coping with possible head tilts and consequent iris rotations\n",
        "# during acquisition. The distance is a positive real number.\n",
        "def match(descriptions_1, mask_1, descriptions_2, mask_2, rotations=16):\n",
        "    # holds the distances computed for each rotation\n",
        "    rot_distances = []\n",
        "\n",
        "    # for each rotation...\n",
        "    for rotation in range(-rotations, rotations + 1):\n",
        "        # holds the BSIF-filter-wise pairwise description distances\n",
        "        distances = []\n",
        "\n",
        "        # for each BSIF-filter-wise description\n",
        "        for i in range(descriptions_1.shape[2]):  # could be \"for i in range(descriptions_2.shape[2]):\"\n",
        "            # rotates description 2 and compares to 1\n",
        "            desc_1 = descriptions_1[:, :, i]\n",
        "            rot_desc_2 = _rotate_norm_image(descriptions_2[:, :, i], rotation)\n",
        "            rot_mask_2 = _rotate_norm_image(mask_2, rotation)\n",
        "\n",
        "            # computes and stores the current distance\n",
        "            distances.append(_compute_norm_hamming_distance(desc_1, mask_1, rot_desc_2, rot_mask_2))\n",
        "\n",
        "        # takes the resulting rotation distance as the average\n",
        "        rot_distances.append(np.mean(distances))\n",
        "\n",
        "    # returns the final distance as the minimum one (best rotation match)\n",
        "    return np.min(rot_distances)"
      ],
      "metadata": {
        "id": "jhrDlXMDPsxy"
      },
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# tests the matching function\n",
        "iris_1 = acquire_from_file('/content/eye_011.png')\n",
        "iris_2 = acquire_from_file('/content/eye_012.png')\n",
        "\n",
        "norm_iris_1, mask_iris_1 = enhance(iris_1)\n",
        "norm_iris_2, mask_iris_2 = enhance(iris_2)\n",
        "\n",
        "desc_1 = describe(norm_iris_1)\n",
        "desc_2 = describe(norm_iris_2)\n",
        "\n",
        "distance = match(desc_1, mask_iris_1, desc_2, mask_iris_2)\n",
        "print('Distance:', distance)"
      ],
      "metadata": {
        "id": "MY2RkKOCQlAu",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 356
        },
        "outputId": "186f2f2c-e181-41f5-a59c-061e3644514a"
      },
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "error",
          "ename": "AttributeError",
          "evalue": "'NoneType' object has no attribute 'shape'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-33-1cb273cbb5bb>\u001b[0m in \u001b[0;36m<cell line: 5>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0miris_2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0macquire_from_file\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'/content/eye_012.png'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0mnorm_iris_1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmask_iris_1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0menhance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miris_1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m \u001b[0mnorm_iris_2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmask_iris_2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0menhance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miris_2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-26-2328beccf13b>\u001b[0m in \u001b[0;36menhance\u001b[0;34m(iris, view)\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0menhance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miris\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mview\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0;31m# pre-processes the iris\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m     \u001b[0mpp_iris\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_01_preprocess\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miris\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mview\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mview\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m     \u001b[0;31m# detects the pupil\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-16-1864878c99f9>\u001b[0m in \u001b[0;36m_01_preprocess\u001b[0;34m(iris, iris_width, view)\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0m_01_preprocess\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miris\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0miris_width\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m640\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mview\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0;31m# makes the iris grayscale, if it has color information\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m     \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miris\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m2\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0miris\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# more than one channel?\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m         \u001b[0miris\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcv2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcvtColor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miris\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcv2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mCOLOR_BGR2GRAY\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mAttributeError\u001b[0m: 'NoneType' object has no attribute 'shape'"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "---\n",
        "## Exercise\n",
        "Compute the distances for all the possible iris pairs:\n",
        "1. <code>/content/eye_011.png</code> versus <code>/content/eye_012.png</code>\n",
        "2. <code>/content/eye_011.png</code> versus <code>/content/eye_021.png</code>\n",
        "3. <code>/content/eye_011.png</code> versus <code>/content/eye_022.png</code>\n",
        "4. <code>/content/eye_012.png</code> versus <code>/content/eye_021.png</code>\n",
        "5. <code>/content/eye_012.png</code> versus <code>/content/eye_022.png</code>\n",
        "6. <code>/content/eye_021.png</code> versus <code>/content/eye_022.png</code>\n",
        "\n",
        "Do the distance values make sense?"
      ],
      "metadata": {
        "id": "5iUPetcSSAAd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import cv2\n",
        "\n",
        "def process_iris(file_path):\n",
        "    iris = acquire_from_file(file_path)\n",
        "    # Check if acquire_from_file returns a valid image\n",
        "    if iris is None:\n",
        "        print(f\"Error: Could not acquire image from {file_path}\")\n",
        "        return None, None # Return None for both values if image acquisition fails\n",
        "    norm_iris, mask_iris = enhance(iris)\n",
        "    desc = describe(norm_iris)\n",
        "    return desc, mask_iris\n",
        "\n",
        "def compute_distances(file_paths):\n",
        "    processed_irises = [process_iris(path) for path in file_paths]\n",
        "    distances = {}\n",
        "\n",
        "    for i in range(len(file_paths)):\n",
        "        for j in range(i+1, len(file_paths)):\n",
        "            desc1, mask1 = processed_irises[i]\n",
        "            desc2, mask2 = processed_irises[j]\n",
        "            # Check if both irises were processed successfully\n",
        "            if desc1 is None or desc2 is None:\n",
        "                print(f\"Error: Could not process one or both irises for comparison.\")\n",
        "                continue # Skip to the next iteration if processing failed\n",
        "            distance = match(desc1, mask1, desc2, mask2)\n",
        "            pair = (file_paths[i], file_paths[j])\n",
        "            distances[pair] = distance\n",
        "\n",
        "    return distances\n",
        "\n",
        "iris_files = [\n",
        "    '/content/eye_011.png',\n",
        "    '/content/eye_012.png',\n",
        "    '/content/eye_021.png',\n",
        "    '/content/eye_022.png'\n",
        "]\n",
        "\n",
        "all_distances = compute_distances(iris_files)\n",
        "\n",
        "for pair, distance in all_distances.items():\n",
        "    print(f\"Distance between {pair[0]} and {pair[1]}: {distance}\")\n",
        "\n",
        "plt.figure(figsize=(10, 6))\n",
        "plt.bar(range(len(all_distances)), list(all_distances.values()), align='center')\n",
        "plt.xticks(range(len(all_distances)), [f\"{p[0][-7:-4]} vs {p[1][-7:-4]}\" for p in all_distances.keys()], rotation=45)\n",
        "plt.ylabel('Distance')\n",
        "plt.title('Iris Matching Distances')\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 781
        },
        "id": "z6FRtArK81xY",
        "outputId": "c63be2d5-1bba-4558-f400-a9877dd044bd"
      },
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Error: Could not acquire image from /content/eye_011.png\n",
            "Error: Could not acquire image from /content/eye_012.png\n",
            "Error: Could not acquire image from /content/eye_021.png\n",
            "Error: Could not acquire image from /content/eye_022.png\n",
            "Error: Could not process one or both irises for comparison.\n",
            "Error: Could not process one or both irises for comparison.\n",
            "Error: Could not process one or both irises for comparison.\n",
            "Error: Could not process one or both irises for comparison.\n",
            "Error: Could not process one or both irises for comparison.\n",
            "Error: Could not process one or both irises for comparison.\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1000x600 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    }
  ]
}